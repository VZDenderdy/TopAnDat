{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcced4fd-ae75-48b8-ad99-d7976bf2d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from phd import get_phd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import modeling_utils\n",
    "if not hasattr(modeling_utils, \"ALL_PARALLEL_STYLES\") or modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\", \"colwise\", 'rowwise']\n",
    "\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class AddDeleteWordAnalyzer:\n",
    "    def __init__(self, tokenizer, number_of_texts=3, number_of_words_per_text=15, n_tries=10):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.number_of_texts = number_of_texts\n",
    "        self.number_of_words_per_text = number_of_words_per_text\n",
    "        self.n_tries = n_tries\n",
    "\n",
    "    def delete_word(self, texts):\n",
    "        word2diff_phd = dict()\n",
    "        for _ in tqdm(range(self.number_of_texts)): # 40\n",
    "            print(len(texts))\n",
    "            text = texts[np.random.choice(len(texts))]\n",
    "            tokenized = tokenizer(text)['input_ids'][1:-1]\n",
    "            df_example = pd.DataFrame({'text': [text]})\n",
    "            true_phd = get_phd(df_example)[0][0]\n",
    "            entropies = self.get_entropy_of_text(text)\n",
    "            \n",
    "            for i in np.random.choice(len(tokenized), size=self.number_of_words_per_text): # 10\n",
    "                new_text = tokenizer.decode(tokenized[:i] + tokenized[i + 1:])# ' '.join(tokenized[:i] + tokenized[i + 1:])\n",
    "                df_new = pd.DataFrame({'text': [new_text]})\n",
    "                new_phd = get_phd(df_new, n_tries=self.n_tries)[0][0]\n",
    "                word2diff_phd[tokenized[i]] = true_phd - new_phd, text, entropies[i]\n",
    "            \n",
    "        df_stats2 = pd.DataFrame(pd.Series(word2diff_phd), columns=['diff_phd']).sort_values(by='diff_phd')\n",
    "        return df_stats2\n",
    "\n",
    "    def get_entropy_of_text(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        output = model(**inputs)\n",
    "        probs = torch.softmax(output.logits.float(), dim=1)\n",
    "        raw_entropy = -(probs * torch.log(probs)).detach().data.sum(axis=-1)\n",
    "        result = list(\n",
    "            zip(\n",
    "                raw_entropy.reshape(-1).tolist(),\n",
    "                [tokenizer.decode([token_id]) for token_id in inputs['input_ids'].reshape(-1)]\n",
    "            )\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22eba8f-f255-4fac-9afe-17f59c14511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/train-00000-of-00009.parquet\")\n",
    "analyzer = AddDeleteWordAnalyzer(tokenizer)\n",
    "human_texts = df.query(\"model == 'human'\")['generation'].values.tolist()\n",
    "llm_texts = df.query(\"model != 'human'\")['generation'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844504c1-6934-4c0b-8564-ceadde16bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.14s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:26<00:00, 27.00s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.33s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.31s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.38s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.44s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.63s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 28.00s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.88s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.32s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.32s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.48s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.29s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.22s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:27<00:00, 27.92s/it]\u001b[A\n",
      " 33%|██████████████▋                             | 1/3 [08:18<16:37, 498.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.28s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.10s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.76s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.91s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.70s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.68s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.63s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.98s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:32<00:00, 32.04s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:31<00:00, 31.91s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:32<00:00, 32.01s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:32<00:00, 32.37s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:32<00:00, 32.29s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:33<00:00, 33.44s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:32<00:00, 32.05s/it]\u001b[A\n",
      " 67%|█████████████████████████████▎              | 2/3 [17:59<09:07, 547.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.83s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.60s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:26<00:00, 26.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.64s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.75s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.90s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.69s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.61s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:26<00:00, 26.45s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:28<00:00, 28.84s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.96s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.22s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:25<00:00, 25.24s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.93s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:24<00:00, 24.96s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████| 3/3 [25:47<00:00, 515.71s/it]\n"
     ]
    }
   ],
   "source": [
    "human_stats = analyzer.delete_word(human_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00162c47-1828-47d3-ac50-266a1a3fea13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.114667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000  0.114667\n",
       "entropy               0.114667  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 text 15 samples 100 tries\n",
    "human_stats['diff_phd_value'] = human_stats['diff_phd'].apply(lambda x: x[0])\n",
    "human_stats['entropy'] = human_stats['diff_phd'].apply(lambda x: x[2][0])\n",
    "human_stats[['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e6a2458-ac07-475b-aee1-134de0ca2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_stats['text'] = human_stats['diff_phd'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09cc6a2b-bfe5-4d21-ae5c-1101000d1e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.104097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000  0.104097\n",
       "entropy               0.104097  1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_stats.sort_values(by='text').iloc[:13, :][['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b53b2915-d645-413e-87c1-2697bb85db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.005366</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000  0.005366\n",
       "entropy               0.005366  1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_stats.sort_values(by='text').iloc[13:28, :][['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1646ebd3-2db5-4aaf-9596-f2f7ce8eb20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd</th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0.18132130237780686, The Amazing Maurice is a...</td>\n",
       "      <td>0.181321</td>\n",
       "      <td>1702.501709</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14242</th>\n",
       "      <td>(0.3972139855624235, The Amazing Maurice is a ...</td>\n",
       "      <td>0.397214</td>\n",
       "      <td>3710.478516</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54437</th>\n",
       "      <td>(0.32868643098476547, The Amazing Maurice is a...</td>\n",
       "      <td>0.328686</td>\n",
       "      <td>1629.284058</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>(0.3179930360771763, The Amazing Maurice is a ...</td>\n",
       "      <td>0.317993</td>\n",
       "      <td>2192.304688</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>(0.29365844362233773, The Amazing Maurice is a...</td>\n",
       "      <td>0.293658</td>\n",
       "      <td>791.112915</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>(0.2283592644532053, The Amazing Maurice is a ...</td>\n",
       "      <td>0.228359</td>\n",
       "      <td>2930.441895</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>(0.21113004239530042, The Amazing Maurice is a...</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>1127.702393</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33168</th>\n",
       "      <td>(0.20375713858670075, The Amazing Maurice is a...</td>\n",
       "      <td>0.203757</td>\n",
       "      <td>2292.721680</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36533</th>\n",
       "      <td>(0.13318295813868097, The Amazing Maurice is a...</td>\n",
       "      <td>0.133183</td>\n",
       "      <td>5973.013672</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34917</th>\n",
       "      <td>(0.11322806732148827, The Amazing Maurice is a...</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>3305.260254</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>(0.12021382184469154, The Amazing Maurice is a...</td>\n",
       "      <td>0.120214</td>\n",
       "      <td>1491.162964</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>(0.022139614936280694, The Amazing Maurice is ...</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>2122.667969</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>(0.09209712799188097, The Amazing Maurice is a...</td>\n",
       "      <td>0.092097</td>\n",
       "      <td>1770.801758</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(0.06499372015787053, The Amazing Maurice is a...</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>1303.191650</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31502</th>\n",
       "      <td>(0.12238943505679245, The Amazing Maurice is a...</td>\n",
       "      <td>0.122389</td>\n",
       "      <td>2300.500732</td>\n",
       "      <td>The Amazing Maurice is a sentient cat who lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                diff_phd  diff_phd_value  \\\n",
       "11     (0.18132130237780686, The Amazing Maurice is a...        0.181321   \n",
       "14242  (0.3972139855624235, The Amazing Maurice is a ...        0.397214   \n",
       "54437  (0.32868643098476547, The Amazing Maurice is a...        0.328686   \n",
       "6199   (0.3179930360771763, The Amazing Maurice is a ...        0.317993   \n",
       "902    (0.29365844362233773, The Amazing Maurice is a...        0.293658   \n",
       "722    (0.2283592644532053, The Amazing Maurice is a ...        0.228359   \n",
       "4332   (0.21113004239530042, The Amazing Maurice is a...        0.211130   \n",
       "33168  (0.20375713858670075, The Amazing Maurice is a...        0.203757   \n",
       "36533  (0.13318295813868097, The Amazing Maurice is a...        0.133183   \n",
       "34917  (0.11322806732148827, The Amazing Maurice is a...        0.113228   \n",
       "281    (0.12021382184469154, The Amazing Maurice is a...        0.120214   \n",
       "374    (0.022139614936280694, The Amazing Maurice is ...        0.022140   \n",
       "1410   (0.09209712799188097, The Amazing Maurice is a...        0.092097   \n",
       "26     (0.06499372015787053, The Amazing Maurice is a...        0.064994   \n",
       "31502  (0.12238943505679245, The Amazing Maurice is a...        0.122389   \n",
       "\n",
       "           entropy                                               text  \n",
       "11     1702.501709  The Amazing Maurice is a sentient cat who lead...  \n",
       "14242  3710.478516  The Amazing Maurice is a sentient cat who lead...  \n",
       "54437  1629.284058  The Amazing Maurice is a sentient cat who lead...  \n",
       "6199   2192.304688  The Amazing Maurice is a sentient cat who lead...  \n",
       "902     791.112915  The Amazing Maurice is a sentient cat who lead...  \n",
       "722    2930.441895  The Amazing Maurice is a sentient cat who lead...  \n",
       "4332   1127.702393  The Amazing Maurice is a sentient cat who lead...  \n",
       "33168  2292.721680  The Amazing Maurice is a sentient cat who lead...  \n",
       "36533  5973.013672  The Amazing Maurice is a sentient cat who lead...  \n",
       "34917  3305.260254  The Amazing Maurice is a sentient cat who lead...  \n",
       "281    1491.162964  The Amazing Maurice is a sentient cat who lead...  \n",
       "374    2122.667969  The Amazing Maurice is a sentient cat who lead...  \n",
       "1410   1770.801758  The Amazing Maurice is a sentient cat who lead...  \n",
       "26     1303.191650  The Amazing Maurice is a sentient cat who lead...  \n",
       "31502  2300.500732  The Amazing Maurice is a sentient cat who lead...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_stats.sort_values(by='text').iloc[13:28, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eae33140-d8cb-407c-99e7-b47e5d3425ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.108697</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000  0.108697\n",
       "entropy               0.108697  1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_stats.sort_values(by='text').iloc[28:, :][['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "837f57e1-4130-4efb-8e8e-27ce6beb5ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_stats['diff_phd_value'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3e5806-ea65-450c-859b-ead949d8ddec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.579499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>-0.579499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000 -0.579499\n",
       "entropy              -0.579499  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 text 15 samples 50 tries\n",
    "human_stats['diff_phd_value'] = human_stats['diff_phd'].apply(lambda x: x[0])\n",
    "human_stats['entropy'] = human_stats['diff_phd'].apply(lambda x: x[2][0])\n",
    "human_stats[['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50fb797a-260f-478a-a658-bab31413fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"human_# 3 text 15 samples 100 tries .pickle\", 'wb') as fd:\n",
    "    pickle.dump(human_stats, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25b6b54d-5124-43b5-aa3d-df23749a37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"human_stats.pickle\", \"wb\") as fd:\n",
    "    pickle.dump(human_stats, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a810809e-0e2c-4abc-9d5f-7849677f35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "\n",
    "with open(\"human_stats.pickle\", \"rb\") as fd:\n",
    "    human_stats = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6c9fca2-3348-4043-8314-cdd3a96a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"llm_stats.pickle\", \"wb\") as fd:\n",
    "    pickle.dump(llm_stats, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8ace8e-3bfa-4a50-9614-47a3629c1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "\n",
    "with open(\"llm_stats.pickle\", \"rb\") as fd:\n",
    "    llm_stats = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c7639d0-e5e8-4420-9c4a-1bc5f3a45a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.52s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.67s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.71s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.72s/it]\u001b[A\n",
      " 33%|██████████████▋                             | 1/3 [02:08<04:17, 128.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.87s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.87s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.87s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.88s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      " 67%|█████████████████████████████▎              | 2/3 [04:15<02:07, 127.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.87s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.72s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.66s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.72s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.80s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.77s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/it]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████| 3/3 [06:22<00:00, 127.62s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_stats = analyzer.delete_word(llm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e32351-e2c8-4103-94e4-af510ae90c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_phd_value</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_phd_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.148827</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_phd_value   entropy\n",
       "diff_phd_value        1.000000  0.148827\n",
       "entropy               0.148827  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_stats\n",
    "# 1 text 15 samples 50 tries\n",
    "llm_stats['diff_phd_value'] = llm_stats['diff_phd'].apply(lambda x: x[0])\n",
    "llm_stats['entropy'] = llm_stats['diff_phd'].apply(lambda x: x[2][0])\n",
    "llm_stats[['diff_phd_value', 'entropy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c77edae-60a2-4f3b-8d2e-c594a4d8c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_stats['diff_phd_value'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5182c010-7a02-4900-824d-801f88d306ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"llm_# 3 text 15 samples 10 tries .pickle\", 'wb') as fd:\n",
    "    pickle.dump(llm_stats, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ed9d7-186c-4ed9-bfc3-b937936779f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d276eb88-399c-437b-8667-7dd2bac5b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_stats['diff_phd_value'] = human_stats['diff_phd'].apply(lambda x: x[0])\n",
    "human_stats['diff_phd_value'].hist(bins=30, alpha=0.3, density=True)\n",
    "llm_stats['diff_phd_value'] = llm_stats['diff_phd'].apply(lambda x: x[0])\n",
    "llm_stats['diff_phd_value'].hist(bins=30, alpha=0.4, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08c517d-8f83-4356-bebf-04473e8559cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "model_id = \"Qwen/Qwen3-1.7B\"\n",
    "llm = ChatOllama(\n",
    "        #    model=model_id # TODO: Загрузите модель в базовый класс LangChain LLM\n",
    "    model=\"Qwen/Qwen3-1.7B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bff367ff-b447-45c5-8a6c-9d4264b50572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='Qwen/Qwen3-1.7B')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7472f3-8ee3-4f29-b8fc-ef328a25ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071e085a-4753-4b9d-bdff-a767b3c55566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 1024)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n)'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:470\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 1024)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n)'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m name_small \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen3-0.6B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m model_1b \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(name_small)\n\u001b[0;32m----> 8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1b\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:950\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 950\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    952\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:782\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    779\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    781\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 782\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:312\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    255\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:522\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    523\u001b[0m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[1;32m    524\u001b[0m ]\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:523\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[1;32m    522\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 523\u001b[0m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[1;32m    524\u001b[0m ]\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:140\u001b[0m, in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cache_file_to_return\u001b[39m(\n\u001b[1;32m    137\u001b[0m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m, full_filename: \u001b[38;5;28mstr\u001b[39m, cache_dir: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m ):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file \u001b[38;5;241m!=\u001b[39m _CACHED_NO_EXIST:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have -- or .. in repo_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 1024)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n)'."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "name_small = \"Qwen/Qwen3-0.6B\"\n",
    "model_1b = AutoModelForCausalLM.from_pretrained(name_small)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720b917e-e90e-4b48-bfc1-97182abc4176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ffbc65102e44979a64de090ab1f540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7525cd31fd41a68dc8293382dd2fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699f7dbf3f7648fa81e119d3a08ce0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac194ee047840bc846ad830f4935640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ca73da3-9a47-4787-8a1c-1b38808cafbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1cbbbd2-322b-4313-b2c2-93f8ea8ade9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In': 17212.50390625,\n",
       " ' decimal': 11909.56640625,\n",
       " ',': 13758.966796875,\n",
       " ' ': 15630.396484375,\n",
       " '1': 14006.720703125,\n",
       " ' +': 12386.314453125,\n",
       " ' =': 11112.3662109375,\n",
       " '2': 12467.447265625,\n",
       " '.': 16577.08203125,\n",
       " ' But': 21412.568359375,\n",
       " ' how': 8339.4462890625,\n",
       " ' does': 16115.833984375,\n",
       " ' that': 10088.302734375,\n",
       " ' translate': 12013.2529296875,\n",
       " ' to': 18076.630859375,\n",
       " ' base': 8488.306640625,\n",
       " '?': 8337.84375,\n",
       " ' Well': 14279.7255859375,\n",
       " ' in': 8887.9443359375,\n",
       " ' binary': 6289.33251953125}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04214703-98a5-4c11-b609-3581a826c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-23869.3281, -12343.6689,  -8613.9189, -11498.9814, -13245.0820,\n",
       "          -8644.3516, -11733.2510,  -9959.1279, -11789.9854,  -6067.7529,\n",
       "         -11440.5996, -24376.4180, -15558.9209,  -9977.2939,  -5527.4424,\n",
       "          -7245.9502,  -4809.2744,  -5951.1528,  -6038.8965]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(probs * torch.log(probs)).detach().data.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b80ced4-db5d-4088-a50e-bbb1d857d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "inputs['input_ids'] = torch.tensor(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df074d3f-9596-438d-91d3-c834937d1667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_pair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_pair_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtruncation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruncationStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_side\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_token_type_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_overflowing_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_offsets_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEncoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           Qwen2TokenizerFast\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "Qwen2TokenizerFast(name_or_path='Qwen/Qwen3-0.6B', vocab_size=151643, model_max_length=131072, is <...> (\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "           }\n",
       "           )\n",
       "\u001b[0;31mLength:\u001b[0m         151669\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.10/site-packages/transformers/models/qwen2/tokenization_qwen2_fast.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Construct a \"fast\" Qwen2 tokenizer (backed by HuggingFace's *tokenizers* library). Based on byte-level\n",
       "Byte-Pair-Encoding.\n",
       "\n",
       "Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will\n",
       "be encoded differently whether it is at the beginning of the sentence (without space) or not:\n",
       "\n",
       "```python\n",
       ">>> from transformers import Qwen2TokenizerFast\n",
       "\n",
       ">>> tokenizer = Qwen2TokenizerFast.from_pretrained(\"Qwen/Qwen-tokenizer\")\n",
       ">>> tokenizer(\"Hello world\")[\"input_ids\"]\n",
       "[9707, 1879]\n",
       "\n",
       ">>> tokenizer(\" Hello world\")[\"input_ids\"]\n",
       "[21927, 1879]\n",
       "```\n",
       "This is expected.\n",
       "\n",
       "This tokenizer inherits from [`PreTrainedTokenizerFast`] which contains most of the main methods. Users should\n",
       "refer to this superclass for more information regarding those methods.\n",
       "\n",
       "Args:\n",
       "    vocab_file (`str`, *optional*):\n",
       "        Path to the vocabulary file.\n",
       "    merges_file (`str`, *optional*):\n",
       "        Path to the merges file.\n",
       "    tokenizer_file (`str`, *optional*):\n",
       "        Path to [tokenizers](https://github.com/huggingface/tokenizers) file (generally has a .json extension) that\n",
       "        contains everything needed to load the tokenizer.\n",
       "    unk_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
       "        token instead. Not applicable to this tokenizer.\n",
       "    bos_token (`str`, *optional*):\n",
       "        The beginning of sequence token. Not applicable for this tokenizer.\n",
       "    eos_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The end of sequence token.\n",
       "    pad_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The token used for padding, for example when batching sequences of different lengths.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "Main method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of\n",
       "sequences.\n",
       "\n",
       "Args:\n",
       "    text (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_pair (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_target (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded as target texts. Each sequence can be a string or a\n",
       "        list of strings (pretokenized string). If the sequences are provided as list of strings (pretokenized),\n",
       "        you must set `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_pair_target (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded as target texts. Each sequence can be a string or a\n",
       "        list of strings (pretokenized string). If the sequences are provided as list of strings (pretokenized),\n",
       "        you must set `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "\n",
       "    add_special_tokens (`bool`, *optional*, defaults to `True`):\n",
       "        Whether or not to add special tokens when encoding the sequences. This will use the underlying\n",
       "        `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines which tokens are\n",
       "        automatically added to the input ids. This is useful if you want to add `bos` or `eos` tokens\n",
       "        automatically.\n",
       "    padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `False`):\n",
       "        Activates and controls padding. Accepts the following values:\n",
       "\n",
       "        - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
       "          sequence if provided).\n",
       "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
       "          acceptable input length for the model if that argument is not provided.\n",
       "        - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n",
       "          lengths).\n",
       "    truncation (`bool`, `str` or [`~tokenization_utils_base.TruncationStrategy`], *optional*, defaults to `False`):\n",
       "        Activates and controls truncation. Accepts the following values:\n",
       "\n",
       "        - `True` or `'longest_first'`: Truncate to a maximum length specified with the argument `max_length` or\n",
       "          to the maximum acceptable input length for the model if that argument is not provided. This will\n",
       "          truncate token by token, removing a token from the longest sequence in the pair if a pair of\n",
       "          sequences (or a batch of pairs) is provided.\n",
       "        - `'only_first'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
       "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        - `'only_second'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
       "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        - `False` or `'do_not_truncate'` (default): No truncation (i.e., can output batch with sequence lengths\n",
       "          greater than the model maximum admissible input size).\n",
       "    max_length (`int`, *optional*):\n",
       "        Controls the maximum length to use by one of the truncation/padding parameters.\n",
       "\n",
       "        If left unset or set to `None`, this will use the predefined model maximum length if a maximum length\n",
       "        is required by one of the truncation/padding parameters. If the model has no specific maximum input\n",
       "        length (like XLNet) truncation/padding to a maximum length will be deactivated.\n",
       "    stride (`int`, *optional*, defaults to 0):\n",
       "        If set to a number along with `max_length`, the overflowing tokens returned when\n",
       "        `return_overflowing_tokens=True` will contain some tokens from the end of the truncated sequence\n",
       "        returned to provide some overlap between truncated and overflowing sequences. The value of this\n",
       "        argument defines the number of overlapping tokens.\n",
       "    is_split_into_words (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not the input is already pre-tokenized (e.g., split into words). If set to `True`, the\n",
       "        tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)\n",
       "        which it will tokenize. This is useful for NER or token classification.\n",
       "    pad_to_multiple_of (`int`, *optional*):\n",
       "        If set will pad the sequence to a multiple of the provided value. Requires `padding` to be activated.\n",
       "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n",
       "        `>= 7.5` (Volta).\n",
       "    padding_side (`str`, *optional*):\n",
       "        The side on which the model should have padding applied. Should be selected between ['right', 'left'].\n",
       "        Default value is picked from the class attribute of the same name.\n",
       "    return_tensors (`str` or [`~utils.TensorType`], *optional*):\n",
       "        If set, will return tensors instead of list of python integers. Acceptable values are:\n",
       "\n",
       "        - `'tf'`: Return TensorFlow `tf.constant` objects.\n",
       "        - `'pt'`: Return PyTorch `torch.Tensor` objects.\n",
       "        - `'np'`: Return Numpy `np.ndarray` objects.\n",
       "\n",
       "    return_token_type_ids (`bool`, *optional*):\n",
       "        Whether to return token type IDs. If left to the default, will return the token type IDs according to\n",
       "        the specific tokenizer's default, defined by the `return_outputs` attribute.\n",
       "\n",
       "        [What are token type IDs?](../glossary#token-type-ids)\n",
       "    return_attention_mask (`bool`, *optional*):\n",
       "        Whether to return the attention mask. If left to the default, will return the attention mask according\n",
       "        to the specific tokenizer's default, defined by the `return_outputs` attribute.\n",
       "\n",
       "        [What are attention masks?](../glossary#attention-mask)\n",
       "    return_overflowing_tokens (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return overflowing token sequences. If a pair of sequences of input ids (or a batch\n",
       "        of pairs) is provided with `truncation_strategy = longest_first` or `True`, an error is raised instead\n",
       "        of returning overflowing tokens.\n",
       "    return_special_tokens_mask (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return special tokens mask information.\n",
       "    return_offsets_mapping (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return `(char_start, char_end)` for each token.\n",
       "\n",
       "        This is only available on fast tokenizers inheriting from [`PreTrainedTokenizerFast`], if using\n",
       "        Python's tokenizer, this method will raise `NotImplementedError`.\n",
       "    return_length  (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return the lengths of the encoded inputs.\n",
       "    verbose (`bool`, *optional*, defaults to `True`):\n",
       "        Whether or not to print more information and warnings.\n",
       "    **kwargs: passed to the `self.tokenize()` method\n",
       "\n",
       "Return:\n",
       "    [`BatchEncoding`]: A [`BatchEncoding`] with the following fields:\n",
       "\n",
       "    - **input_ids** -- List of token ids to be fed to a model.\n",
       "\n",
       "      [What are input IDs?](../glossary#input-ids)\n",
       "\n",
       "    - **token_type_ids** -- List of token type ids to be fed to a model (when `return_token_type_ids=True` or\n",
       "      if *\"token_type_ids\"* is in `self.model_input_names`).\n",
       "\n",
       "      [What are token type IDs?](../glossary#token-type-ids)\n",
       "\n",
       "    - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when\n",
       "      `return_attention_mask=True` or if *\"attention_mask\"* is in `self.model_input_names`).\n",
       "\n",
       "      [What are attention masks?](../glossary#attention-mask)\n",
       "\n",
       "    - **overflowing_tokens** -- List of overflowing tokens sequences (when a `max_length` is specified and\n",
       "      `return_overflowing_tokens=True`).\n",
       "    - **num_truncated_tokens** -- Number of tokens truncated (when a `max_length` is specified and\n",
       "      `return_overflowing_tokens=True`).\n",
       "    - **special_tokens_mask** -- List of 0s and 1s, with 1 specifying added special tokens and 0 specifying\n",
       "      regular sequence tokens (when `add_special_tokens=True` and `return_special_tokens_mask=True`).\n",
       "    - **length** -- The length of the inputs (when `return_length=True`)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999ca36-1860-47b2-84a6-a62102504e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
