{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5b63a6-d672-44e2-98f9-176ef0e6f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from phd import get_phd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import modeling_utils\n",
    "if not hasattr(modeling_utils, \"ALL_PARALLEL_STYLES\") or modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\", \"colwise\", 'rowwise']\n",
    "\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class AddDeleteWordAnalyzer:\n",
    "    def __init__(self, tokenizer, number_of_texts=3, number_of_words_per_text=15, n_tries=10):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.number_of_texts = number_of_texts\n",
    "        self.number_of_words_per_text = number_of_words_per_text\n",
    "        self.n_tries = n_tries\n",
    "\n",
    "    def delete_word(self, texts):\n",
    "        word2diff_phd = dict()\n",
    "        for _ in tqdm(range(self.number_of_texts)): # 40\n",
    "            print(len(texts))\n",
    "            text = texts[np.random.choice(len(texts))]\n",
    "            tokenized = tokenizer(text)['input_ids'][1:-1]\n",
    "            df_example = pd.DataFrame({'text': [text]})\n",
    "            true_phd = get_phd(df_example)[0][0]\n",
    "            entropies = self.get_entropy_of_text(text)\n",
    "            \n",
    "            for i in np.random.choice(len(tokenized), size=self.number_of_words_per_text): # 10\n",
    "                new_text = tokenizer.decode(tokenized[:i] + tokenized[i + 1:])# ' '.join(tokenized[:i] + tokenized[i + 1:])\n",
    "                df_new = pd.DataFrame({'text': [new_text]})\n",
    "                new_phd = get_phd(df_new, n_tries=self.n_tries)[0][0]\n",
    "                word2diff_phd[tokenized[i]] = true_phd - new_phd, text, entropies[i]\n",
    "            \n",
    "        df_stats2 = pd.DataFrame(pd.Series(word2diff_phd), columns=['diff_phd']).sort_values(by='diff_phd')\n",
    "        return df_stats2\n",
    "\n",
    "    def get_entropy_of_text(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        output = model(**inputs)\n",
    "        probs = torch.softmax(output.logits.float(), dim=1)\n",
    "        raw_entropy = -(probs * torch.log(probs)).detach().data.sum(axis=-1)\n",
    "        result = list(\n",
    "            zip(\n",
    "                raw_entropy.reshape(-1).tolist(),\n",
    "                [tokenizer.decode([token_id]) for token_id in inputs['input_ids'].reshape(-1)]\n",
    "            )\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0134e48-5976-4512-9fd0-952310784a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/train-00000-of-00009.parquet\")\n",
    "analyzer = AddDeleteWordAnalyzer(tokenizer)\n",
    "human_texts = df.query(\"model == 'human'\")['generation'].values.tolist()\n",
    "llm_texts = df.query(\"model != 'human'\")['generation'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0535d7-0f34-4ab5-9508-0430748ff4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Неужели все-таки это iid?\n",
    "## или мб это из-за разброса?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1babaed9-beb3-4e9e-a775-5d66e39d4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99968134]\n",
      " [0.99968134 1.        ]]\n",
      "[[1.         0.99992245]\n",
      " [0.99992245 1.        ]]\n",
      "[[1.         0.99972662]\n",
      " [0.99972662 1.        ]]\n",
      "[[1.         0.99991894]\n",
      " [0.99991894 1.        ]]\n",
      "[[1.         0.99993806]\n",
      " [0.99993806 1.        ]]\n",
      "[[1.         0.99988433]\n",
      " [0.99988433 1.        ]]\n",
      "[[1.         0.99992866]\n",
      " [0.99992866 1.        ]]\n",
      "[[1.         0.99989312]\n",
      " [0.99989312 1.        ]]\n",
      "[[1.         0.99990121]\n",
      " [0.99990121 1.        ]]\n",
      "[[1.         0.99968145]\n",
      " [0.99968145 1.        ]]\n",
      "[[1.         0.99992345]\n",
      " [0.99992345 1.        ]]\n",
      "[[1.         0.99981269]\n",
      " [0.99981269 1.        ]]\n",
      "[[1.         0.99979095]\n",
      " [0.99979095 1.        ]]\n",
      "[[1.         0.99976765]\n",
      " [0.99976765 1.        ]]\n",
      "[[1.        0.9999192]\n",
      " [0.9999192 1.       ]]\n",
      "[[1.         0.99966476]\n",
      " [0.99966476 1.        ]]\n",
      "[[1.         0.99993707]\n",
      " [0.99993707 1.        ]]\n",
      "[[1.         0.99974848]\n",
      " [0.99974848 1.        ]]\n",
      "[[1.         0.99983883]\n",
      " [0.99983883 1.        ]]\n",
      "[[1.         0.99995947]\n",
      " [0.99995947 1.        ]]\n",
      "[[1.         0.99961856]\n",
      " [0.99961856 1.        ]]\n",
      "[[1.         0.99960469]\n",
      " [0.99960469 1.        ]]\n",
      "[[1.        0.9997687]\n",
      " [0.9997687 1.       ]]\n",
      "[[1.         0.99990274]\n",
      " [0.99990274 1.        ]]\n",
      "[[1.         0.99993019]\n",
      " [0.99993019 1.        ]]\n",
      "[[1.         0.99978737]\n",
      " [0.99978737 1.        ]]\n",
      "[[1.         0.99985469]\n",
      " [0.99985469 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99984869]\n",
      " [0.99984869 1.        ]]\n",
      "[[1.        0.9999183]\n",
      " [0.9999183 1.       ]]\n",
      "[[1.         0.99993842]\n",
      " [0.99993842 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "human_phd_new = get_phd(df.query(\"model == 'human'\").sample(1), 'generation', n_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f86d12b-dceb-4d43-a9ad-83483103d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ba48cc-064e-4d6f-8b5b-c66a76925e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99979196]\n",
      " [0.99979196 1.        ]]\n",
      "[[1.         0.99965782]\n",
      " [0.99965782 1.        ]]\n",
      "[[1.        0.9995707]\n",
      " [0.9995707 1.       ]]\n",
      "[[1.         0.99974756]\n",
      " [0.99974756 1.        ]]\n",
      "[[1.        0.9999169]\n",
      " [0.9999169 1.       ]]\n",
      "[[1.         0.99963992]\n",
      " [0.99963992 1.        ]]\n",
      "[[1.         0.99972743]\n",
      " [0.99972743 1.        ]]\n",
      "[[1.         0.99920829]\n",
      " [0.99920829 1.        ]]\n",
      "[[1.        0.9996041]\n",
      " [0.9996041 1.       ]]\n",
      "[[1.         0.99970391]\n",
      " [0.99970391 1.        ]]\n",
      "[[1.         0.99957414]\n",
      " [0.99957414 1.        ]]\n",
      "[[1.         0.99986512]\n",
      " [0.99986512 1.        ]]\n",
      "[[1.         0.99995573]\n",
      " [0.99995573 1.        ]]\n",
      "[[1.        0.9999483]\n",
      " [0.9999483 1.       ]]\n",
      "[[1.         0.99987877]\n",
      " [0.99987877 1.        ]]\n",
      "[[1.         0.99986356]\n",
      " [0.99986356 1.        ]]\n",
      "[[1.         0.99934319]\n",
      " [0.99934319 1.        ]]\n",
      "[[1.         0.99982869]\n",
      " [0.99982869 1.        ]]\n",
      "[[1.         0.99984115]\n",
      " [0.99984115 1.        ]]\n",
      "[[1.         0.99996333]\n",
      " [0.99996333 1.        ]]\n",
      "[[1.         0.99946292]\n",
      " [0.99946292 1.        ]]\n",
      "[[1.         0.99986714]\n",
      " [0.99986714 1.        ]]\n",
      "[[1.         0.99985151]\n",
      " [0.99985151 1.        ]]\n",
      "[[1.         0.99975636]\n",
      " [0.99975636 1.        ]]\n",
      "[[1.        0.9999055]\n",
      " [0.9999055 1.       ]]\n",
      "[[1.         0.99996426]\n",
      " [0.99996426 1.        ]]\n",
      "[[1.         0.99991087]\n",
      " [0.99991087 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99999359]\n",
      " [0.99999359 1.        ]]\n",
      "[[1.         0.99960058]\n",
      " [0.99960058 1.        ]]\n",
      "[[1.         0.99993394]\n",
      " [0.99993394 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "human_phd_new = get_phd(df.query(\"model != 'human'\").sample(1), 'generation', n_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c19ce08-e534-42b9-8584-8e6291e299ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>None</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>None</td>\n",
       "      <td>High-quality training data play a key role in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>None</td>\n",
       "      <td>The success of deep learning methods in medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>None</td>\n",
       "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Detection faults in seismic data is a crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434688</th>\n",
       "      <td>ff6fc5a1-cf57-4a2d-aabd-1c05ac18efd1</td>\n",
       "      <td>94ddbf2c-2ef9-46d1-9b95-65f3ee29d1a5</td>\n",
       "      <td>7d6a4f88-0682-4dd6-a4d5-931495e6636c</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>upper_lower</td>\n",
       "      <td>books</td>\n",
       "      <td>The Hydrogen Sonata</td>\n",
       "      <td>Write the body of a plot summary for a novel t...</td>\n",
       "      <td>In a Distant future, humanity has colonized th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434689</th>\n",
       "      <td>91d3f099-8aec-4911-8f4b-02d025a48db7</td>\n",
       "      <td>1b337f85-6862-4ba7-a409-c01ed4328e23</td>\n",
       "      <td>7d6a4f88-0682-4dd6-a4d5-931495e6636c</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>upper_lower</td>\n",
       "      <td>books</td>\n",
       "      <td>The Hydrogen Sonata</td>\n",
       "      <td>Write the body of a plot summary for a novel t...</td>\n",
       "      <td>In a distant future, humanity has colonized th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434690</th>\n",
       "      <td>8f7193e2-e087-415b-9348-36fb6e1060b8</td>\n",
       "      <td>d628b6ca-3659-49bb-a1a7-73bedacd6abb</td>\n",
       "      <td>4964cb21-cf76-49ca-94d3-f2e653e3e552</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>upper_lower</td>\n",
       "      <td>books</td>\n",
       "      <td>Vampirates:Black Heart</td>\n",
       "      <td>Write the body of a plot summary for a novel t...</td>\n",
       "      <td>In the dark waters of the Caribbean, a legenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434691</th>\n",
       "      <td>620feb1d-9fa2-4102-bfaa-01be48914dba</td>\n",
       "      <td>b9f45522-f1d9-434e-bf77-dde344e59897</td>\n",
       "      <td>4964cb21-cf76-49ca-94d3-f2e653e3e552</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>upper_lower</td>\n",
       "      <td>books</td>\n",
       "      <td>Vampirates:Black Heart</td>\n",
       "      <td>Write the body of a plot summary for a novel t...</td>\n",
       "      <td>In a world where vampires and pirates roam The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434692</th>\n",
       "      <td>64864f66-c773-4711-825f-c91654e59926</td>\n",
       "      <td>d623a784-6252-476a-bc70-84f1d7b537d8</td>\n",
       "      <td>94e2ff1d-3132-4c60-8dff-fa9d6a445bb3</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>upper_lower</td>\n",
       "      <td>books</td>\n",
       "      <td>Well-Schooled in Murder</td>\n",
       "      <td>Write the body of a plot summary for a novel t...</td>\n",
       "      <td>when renowned detective Emily Waters is called...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434693 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  \\\n",
       "0       e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
       "1       f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
       "2       856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
       "3       fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
       "4       72c41b8d-0069-4886-b734-a4000ffca286   \n",
       "...                                      ...   \n",
       "434688  ff6fc5a1-cf57-4a2d-aabd-1c05ac18efd1   \n",
       "434689  91d3f099-8aec-4911-8f4b-02d025a48db7   \n",
       "434690  8f7193e2-e087-415b-9348-36fb6e1060b8   \n",
       "434691  620feb1d-9fa2-4102-bfaa-01be48914dba   \n",
       "434692  64864f66-c773-4711-825f-c91654e59926   \n",
       "\n",
       "                               adv_source_id  \\\n",
       "0       e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
       "1       f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
       "2       856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
       "3       fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
       "4       72c41b8d-0069-4886-b734-a4000ffca286   \n",
       "...                                      ...   \n",
       "434688  94ddbf2c-2ef9-46d1-9b95-65f3ee29d1a5   \n",
       "434689  1b337f85-6862-4ba7-a409-c01ed4328e23   \n",
       "434690  d628b6ca-3659-49bb-a1a7-73bedacd6abb   \n",
       "434691  b9f45522-f1d9-434e-bf77-dde344e59897   \n",
       "434692  d623a784-6252-476a-bc70-84f1d7b537d8   \n",
       "\n",
       "                                   source_id       model  decoding  \\\n",
       "0       e5e058ce-be2b-459d-af36-32532aaba5ff       human      None   \n",
       "1       f95b107b-d176-4af5-90f7-4d0bb20caf93       human      None   \n",
       "2       856d8972-9e3d-4544-babc-0fe16f21e04d       human      None   \n",
       "3       fbc8a5ea-90fa-47b8-8fa7-73dd954f1524       human      None   \n",
       "4       72c41b8d-0069-4886-b734-a4000ffca286       human      None   \n",
       "...                                      ...         ...       ...   \n",
       "434688  7d6a4f88-0682-4dd6-a4d5-931495e6636c  llama-chat    greedy   \n",
       "434689  7d6a4f88-0682-4dd6-a4d5-931495e6636c  llama-chat  sampling   \n",
       "434690  4964cb21-cf76-49ca-94d3-f2e653e3e552  llama-chat    greedy   \n",
       "434691  4964cb21-cf76-49ca-94d3-f2e653e3e552  llama-chat  sampling   \n",
       "434692  94e2ff1d-3132-4c60-8dff-fa9d6a445bb3  llama-chat    greedy   \n",
       "\n",
       "       repetition_penalty       attack     domain  \\\n",
       "0                    None         none  abstracts   \n",
       "1                    None         none  abstracts   \n",
       "2                    None         none  abstracts   \n",
       "3                    None         none  abstracts   \n",
       "4                    None         none  abstracts   \n",
       "...                   ...          ...        ...   \n",
       "434688                 no  upper_lower      books   \n",
       "434689                yes  upper_lower      books   \n",
       "434690                 no  upper_lower      books   \n",
       "434691                yes  upper_lower      books   \n",
       "434692                 no  upper_lower      books   \n",
       "\n",
       "                                                    title  \\\n",
       "0       FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "1       EdgeFlow: Achieving Practical Interactive Segm...   \n",
       "2       Semi-supervised Contrastive Learning for Label...   \n",
       "3       Combo Loss: Handling Input and Output Imbalanc...   \n",
       "4       Attention-Based 3D Seismic Fault Segmentation ...   \n",
       "...                                                   ...   \n",
       "434688                                The Hydrogen Sonata   \n",
       "434689                                The Hydrogen Sonata   \n",
       "434690                             Vampirates:Black Heart   \n",
       "434691                             Vampirates:Black Heart   \n",
       "434692                            Well-Schooled in Murder   \n",
       "\n",
       "                                                   prompt  \\\n",
       "0                                                    None   \n",
       "1                                                    None   \n",
       "2                                                    None   \n",
       "3                                                    None   \n",
       "4                                                    None   \n",
       "...                                                   ...   \n",
       "434688  Write the body of a plot summary for a novel t...   \n",
       "434689  Write the body of a plot summary for a novel t...   \n",
       "434690  Write the body of a plot summary for a novel t...   \n",
       "434691  Write the body of a plot summary for a novel t...   \n",
       "434692  Write the body of a plot summary for a novel t...   \n",
       "\n",
       "                                               generation  \n",
       "0       The recent advancements in artificial intellig...  \n",
       "1       High-quality training data play a key role in ...  \n",
       "2       The success of deep learning methods in medica...  \n",
       "3       Simultaneous segmentation of multiple organs f...  \n",
       "4       Detection faults in seismic data is a crucial ...  \n",
       "...                                                   ...  \n",
       "434688  In a Distant future, humanity has colonized th...  \n",
       "434689  In a distant future, humanity has colonized th...  \n",
       "434690  In the dark waters of the Caribbean, a legenda...  \n",
       "434691  In a world where vampires and pirates roam The...  \n",
       "434692  when renowned detective Emily Waters is called...  \n",
       "\n",
       "[434693 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77705c0f-4340-4443-bdbf-170b2dd2744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## union two different texts:\n",
    "n_samples = 10\n",
    "df = df.query(\"model != 'human'\").iloc[:n_samples, :]\n",
    "new_llm_list = []\n",
    "for i in range(n_samples):\n",
    "    idx = np.random.choice(n_samples)\n",
    "    while idx == i:\n",
    "        idx = np.random.choice(n_samples)\n",
    "    new_llm = df['generation'].iloc[i] + df['generation'].iloc[idx] \n",
    "    new_llm_list.append(new_llm)\n",
    "\n",
    "df['union_llm_completion'] = new_llm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dcd5f0-1775-4c58-97ec-3ee1085cb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99956794]\n",
      " [0.99956794 1.        ]]\n",
      "[[1.         0.99991912]\n",
      " [0.99991912 1.        ]]\n",
      "[[1.         0.99962587]\n",
      " [0.99962587 1.        ]]\n",
      "[[1.         0.99984098]\n",
      " [0.99984098 1.        ]]\n",
      "[[1.         0.99978774]\n",
      " [0.99978774 1.        ]]\n",
      "[[1.         0.99995878]\n",
      " [0.99995878 1.        ]]\n",
      "[[1.         0.99985104]\n",
      " [0.99985104 1.        ]]\n",
      "[[1.         0.99985967]\n",
      " [0.99985967 1.        ]]\n",
      "[[1.         0.99983834]\n",
      " [0.99983834 1.        ]]\n",
      "[[1.         0.99992696]\n",
      " [0.99992696 1.        ]]\n",
      "[[1.         0.99994163]\n",
      " [0.99994163 1.        ]]\n",
      "[[1.         0.99992045]\n",
      " [0.99992045 1.        ]]\n",
      "[[1.         0.99994037]\n",
      " [0.99994037 1.        ]]\n",
      "[[1.         0.99993104]\n",
      " [0.99993104 1.        ]]\n",
      "[[1.         0.99979825]\n",
      " [0.99979825 1.        ]]\n",
      "[[1.         0.99984985]\n",
      " [0.99984985 1.        ]]\n",
      "[[1.         0.99987037]\n",
      " [0.99987037 1.        ]]\n",
      "[[1.         0.99991537]\n",
      " [0.99991537 1.        ]]\n",
      "[[1.         0.99965354]\n",
      " [0.99965354 1.        ]]\n",
      "[[1.         0.99988325]\n",
      " [0.99988325 1.        ]]\n",
      "[[1.         0.99982362]\n",
      " [0.99982362 1.        ]]\n",
      "[[1.         0.99982456]\n",
      " [0.99982456 1.        ]]\n",
      "[[1.         0.99985968]\n",
      " [0.99985968 1.        ]]\n",
      "[[1.         0.99970831]\n",
      " [0.99970831 1.        ]]\n",
      "[[1.         0.99985601]\n",
      " [0.99985601 1.        ]]\n",
      "[[1.         0.99988415]\n",
      " [0.99988415 1.        ]]\n",
      "[[1.         0.99993313]\n",
      " [0.99993313 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99981415]\n",
      " [0.99981415 1.        ]]\n",
      "[[1.         0.99991071]\n",
      " [0.99991071 1.        ]]\n",
      "[[1.         0.99979113]\n",
      " [0.99979113 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "human_phd_new = get_phd(df.sample(1), 'union_llm_completion', n_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b188a8c9-3a21-4f55-9f28-03137637dc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adv_source_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decoding</th>\n",
       "      <th>repetition_penalty</th>\n",
       "      <th>attack</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>union_llm_completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2bd98bd7-3356-43bf-8c5d-69ef336d0536</td>\n",
       "      <td>2bd98bd7-3356-43bf-8c5d-69ef336d0536</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the paper \"FUTURE-AI: Guiding Principles an...</td>\n",
       "      <td>In the paper \"FUTURE-AI: Guiding Principles an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3</td>\n",
       "      <td>e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3</td>\n",
       "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the paper \"Future-AI: Guiding Principles an...</td>\n",
       "      <td>In the paper \"Future-AI: Guiding Principles an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>ee968d29-ce73-4c5d-804d-0a0efec4bea4</td>\n",
       "      <td>ee968d29-ce73-4c5d-804d-0a0efec4bea4</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present EdgeFlow, a novel ap...</td>\n",
       "      <td>In this paper, we present EdgeFlow, a novel ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3d24eb90-f540-490f-81c8-e4a24fd49ad7</td>\n",
       "      <td>3d24eb90-f540-490f-81c8-e4a24fd49ad7</td>\n",
       "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present a novel approach to ...</td>\n",
       "      <td>In this paper, we present a novel approach to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>7389e65b-2e27-4b90-999a-53e28b773315</td>\n",
       "      <td>7389e65b-2e27-4b90-999a-53e28b773315</td>\n",
       "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we propose a novel approach to ...</td>\n",
       "      <td>In this paper, we propose a novel approach to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>8b79a378-67db-48e8-8950-4d3215cfef16</td>\n",
       "      <td>8b79a378-67db-48e8-8950-4d3215cfef16</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In the field of medical image segmentation, im...</td>\n",
       "      <td>In the field of medical image segmentation, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>16742a95-7417-4bca-96c8-cee548681a9b</td>\n",
       "      <td>16742a95-7417-4bca-96c8-cee548681a9b</td>\n",
       "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In medical image segmentation, imbalanced inpu...</td>\n",
       "      <td>In medical image segmentation, imbalanced inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>8c2ca078-bc3f-46fa-9bf4-6fe1d72226fe</td>\n",
       "      <td>8c2ca078-bc3f-46fa-9bf4-6fe1d72226fe</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we propose a novel approach for...</td>\n",
       "      <td>In this paper, we propose a novel approach for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0a0495a4-3c8e-4d29-9cfa-cf8644f2d895</td>\n",
       "      <td>0a0495a4-3c8e-4d29-9cfa-cf8644f2d895</td>\n",
       "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>sampling</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present a novel approach for...</td>\n",
       "      <td>In this paper, we present a novel approach for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>260ac39c-fa06-4e46-a110-fcbc5acff930</td>\n",
       "      <td>260ac39c-fa06-4e46-a110-fcbc5acff930</td>\n",
       "      <td>72fe360b-cce6-4daf-b66a-1d778f5964f8</td>\n",
       "      <td>llama-chat</td>\n",
       "      <td>greedy</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>abstracts</td>\n",
       "      <td>Segmenter: Transformer for Semantic Segmentation</td>\n",
       "      <td>Write the abstract for the academic paper titl...</td>\n",
       "      <td>In this paper, we present Segmenter, a novel a...</td>\n",
       "      <td>In this paper, we present Segmenter, a novel a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "367  2bd98bd7-3356-43bf-8c5d-69ef336d0536   \n",
       "368  e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3   \n",
       "369  ee968d29-ce73-4c5d-804d-0a0efec4bea4   \n",
       "370  3d24eb90-f540-490f-81c8-e4a24fd49ad7   \n",
       "371  7389e65b-2e27-4b90-999a-53e28b773315   \n",
       "372  8b79a378-67db-48e8-8950-4d3215cfef16   \n",
       "373  16742a95-7417-4bca-96c8-cee548681a9b   \n",
       "374  8c2ca078-bc3f-46fa-9bf4-6fe1d72226fe   \n",
       "375  0a0495a4-3c8e-4d29-9cfa-cf8644f2d895   \n",
       "376  260ac39c-fa06-4e46-a110-fcbc5acff930   \n",
       "\n",
       "                            adv_source_id  \\\n",
       "367  2bd98bd7-3356-43bf-8c5d-69ef336d0536   \n",
       "368  e8bdc461-3ff2-4d68-8c7b-cdbc086f62b3   \n",
       "369  ee968d29-ce73-4c5d-804d-0a0efec4bea4   \n",
       "370  3d24eb90-f540-490f-81c8-e4a24fd49ad7   \n",
       "371  7389e65b-2e27-4b90-999a-53e28b773315   \n",
       "372  8b79a378-67db-48e8-8950-4d3215cfef16   \n",
       "373  16742a95-7417-4bca-96c8-cee548681a9b   \n",
       "374  8c2ca078-bc3f-46fa-9bf4-6fe1d72226fe   \n",
       "375  0a0495a4-3c8e-4d29-9cfa-cf8644f2d895   \n",
       "376  260ac39c-fa06-4e46-a110-fcbc5acff930   \n",
       "\n",
       "                                source_id       model  decoding  \\\n",
       "367  e5e058ce-be2b-459d-af36-32532aaba5ff  llama-chat    greedy   \n",
       "368  e5e058ce-be2b-459d-af36-32532aaba5ff  llama-chat  sampling   \n",
       "369  f95b107b-d176-4af5-90f7-4d0bb20caf93  llama-chat    greedy   \n",
       "370  f95b107b-d176-4af5-90f7-4d0bb20caf93  llama-chat  sampling   \n",
       "371  856d8972-9e3d-4544-babc-0fe16f21e04d  llama-chat  sampling   \n",
       "372  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  llama-chat    greedy   \n",
       "373  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  llama-chat  sampling   \n",
       "374  72c41b8d-0069-4886-b734-a4000ffca286  llama-chat    greedy   \n",
       "375  72c41b8d-0069-4886-b734-a4000ffca286  llama-chat  sampling   \n",
       "376  72fe360b-cce6-4daf-b66a-1d778f5964f8  llama-chat    greedy   \n",
       "\n",
       "    repetition_penalty attack     domain  \\\n",
       "367                 no   none  abstracts   \n",
       "368                yes   none  abstracts   \n",
       "369                 no   none  abstracts   \n",
       "370                yes   none  abstracts   \n",
       "371                yes   none  abstracts   \n",
       "372                 no   none  abstracts   \n",
       "373                yes   none  abstracts   \n",
       "374                 no   none  abstracts   \n",
       "375                yes   none  abstracts   \n",
       "376                 no   none  abstracts   \n",
       "\n",
       "                                                 title  \\\n",
       "367  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "368  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "369  EdgeFlow: Achieving Practical Interactive Segm...   \n",
       "370  EdgeFlow: Achieving Practical Interactive Segm...   \n",
       "371  Semi-supervised Contrastive Learning for Label...   \n",
       "372  Combo Loss: Handling Input and Output Imbalanc...   \n",
       "373  Combo Loss: Handling Input and Output Imbalanc...   \n",
       "374  Attention-Based 3D Seismic Fault Segmentation ...   \n",
       "375  Attention-Based 3D Seismic Fault Segmentation ...   \n",
       "376   Segmenter: Transformer for Semantic Segmentation   \n",
       "\n",
       "                                                prompt  \\\n",
       "367  Write the abstract for the academic paper titl...   \n",
       "368  Write the abstract for the academic paper titl...   \n",
       "369  Write the abstract for the academic paper titl...   \n",
       "370  Write the abstract for the academic paper titl...   \n",
       "371  Write the abstract for the academic paper titl...   \n",
       "372  Write the abstract for the academic paper titl...   \n",
       "373  Write the abstract for the academic paper titl...   \n",
       "374  Write the abstract for the academic paper titl...   \n",
       "375  Write the abstract for the academic paper titl...   \n",
       "376  Write the abstract for the academic paper titl...   \n",
       "\n",
       "                                            generation  \\\n",
       "367  In the paper \"FUTURE-AI: Guiding Principles an...   \n",
       "368  In the paper \"Future-AI: Guiding Principles an...   \n",
       "369  In this paper, we present EdgeFlow, a novel ap...   \n",
       "370  In this paper, we present a novel approach to ...   \n",
       "371  In this paper, we propose a novel approach to ...   \n",
       "372  In the field of medical image segmentation, im...   \n",
       "373  In medical image segmentation, imbalanced inpu...   \n",
       "374  In this paper, we propose a novel approach for...   \n",
       "375  In this paper, we present a novel approach for...   \n",
       "376  In this paper, we present Segmenter, a novel a...   \n",
       "\n",
       "                                  union_llm_completion  \n",
       "367  In the paper \"FUTURE-AI: Guiding Principles an...  \n",
       "368  In the paper \"Future-AI: Guiding Principles an...  \n",
       "369  In this paper, we present EdgeFlow, a novel ap...  \n",
       "370  In this paper, we present a novel approach to ...  \n",
       "371  In this paper, we propose a novel approach to ...  \n",
       "372  In the field of medical image segmentation, im...  \n",
       "373  In medical image segmentation, imbalanced inpu...  \n",
       "374  In this paper, we propose a novel approach for...  \n",
       "375  In this paper, we present a novel approach for...  \n",
       "376  In this paper, we present Segmenter, a novel a...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4ed73-a29d-4721-8cc1-c3166a53d814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
